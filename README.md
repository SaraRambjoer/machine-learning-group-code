This document explains the repository structure. 

Folders: 
- 

* /Data/: Contains the dataset 
* /deep_weight_logs/: Contains logs produced by the deep12-model - currently not used for anything, but are supposed to be logs of every network weight per epoch
* /graphs/: Contains every produced graph, names of each graph should be explanatory
* /Logs/: Contains other logs made by the models, most show accuracy and loss per epoch
for different models/hyperparameters. The ones for shallow150 ending with "processed" or "raw" show 
neuron activations for each training sample, "processed" contains a number describing
how many activations where greater than 0.15 for each training sample
* /Models/: Saved models, all are made using keras save functionality except for perceptrons which
are merely the learned weights. 

Files: 
- 
* 150shallow.py: Contains code for creating and training 150relu/sigmoid/leakyrelu-3softmax-categorical crossentropy neural network, and logging
* avgChangeByLayer.txt: Generated by deep_weight_logs_average_change_calculator_tool.py, was supposed to show average change
per layer but we dropped this from the scope of the project - suspected bugs
* credits.txt: Gives credits to stackoverflow answers/other online sources that helped with writing the code - included for transparency
* deep-12.py: Trains the deep neural net, logs it, saves it. 
* deep-12-relu.py: Trains the deep neural net, specifically the relu versions
* deep_weight_logs_average_change_calculator_tool.py: Was supposed to show average change
per layer but we dropped this from the scope of the project - suspected bugs
* depth3.py: Code for training, creating, logging and saving depth3 model
* graph-creator.py: Used for generating the graphs in /graphs/. Uses logfiles from /Logs/
* one_layer.py: Contains code for training perceptrons - our own implementation
* shallow150-inspection.py: Generates data about how many activations there were per training sample
for shallow neural net. 
* visualiseDataSet.py: Generates scatterplots of the dataset a long all possible axis combinations.


Note on reproducability: 
- 
To reproduce the experiments the following steps can be taken: 
1. Run 150shallow.py, deep-12.py, deep-12-relu.py, one_layer.py (perceptrons), and depth3.py. 
2. Run graph-creator.py
3. Run shallow150-inspection.py 

After these steps have been taken the models will have been re-trained and graphs and logfiles will have been created
for the new models. When it comes to hyperparameter selection and graphs this is done by hand/not automatically, 
meaning that if other hyperparameters were to perform better than the ones in the experiment some of the graph
generating code will have to be changed to make the graphs reflect this. 